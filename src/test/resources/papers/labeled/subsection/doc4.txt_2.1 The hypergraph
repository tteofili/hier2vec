
Phrase-based decoding is typically presented as building a lattice, where nodes
represent states (typically shared coverage vectors and target-side language model
context) and arcs represent phrasal extensions. Conceptually, this is what Joshua
does, but internally, it is using the same generalized hypergraph code used in the
syntax-based decoder. To accomplish this, all phrases are read in as hierarchical rules
with a single nonterminal on the left-hand side (essentially, phrases are reinterpreted
as strictly left-branching grammar rules of arity 1). All applications of phrases must

6



Matt Post, Yuan Cao, and Gaurav Kumar Joshua 6 (5–16)

dress

<s>    la    robe    noire    </s>

X[2,3]

0              1          2                3                   4                 5

X[1,4] the ___ black

X[0,5]

X[ ,1]

X[ ,2] X[ ,4] X[ ,3]

X[ ,5]

the black dress

Figure 1. Shared hypergraph format when translating the French sentence la robe noire
into English with the hierarchical (above) and phrase-based (below) decoders. The nodes
are states in the hypergraph and contain the nonterminal label (here, X) and the input

span (hierarchical) or coverage vector and last-translated word (phrase-based), as well as
the target-side words produced by the incoming hyperedge.

extend an existing hypothesis, which is trivial since the stack decoding algorithm is
seeded with an empty hypothesis representing the start of the sentence (Figure 1).

Sharing the hypergraph representation between the decoding algorithms provides
many benefits. Feature functions can be written once and used for both decoders,2
visualization toolswork for both, andhypergraph operations such asminimumBayes’
risk rescoring (Kumar and Byrne, 2004) work without modification.
