
Unlike traditional machine translation, in which output words
and input words are explicitly linked by translation rules, the
input and output in NMT are mapped in sequence level. For-
tunately, the attention mechanism [Bahdanau et al., 2015]
provides a kind of soft alignment which can be used to find
the corresponding source word for each target word. How-
ever, the alignment generated by current attention mechanism
is far from perfect. Some source words are repeatedly at-
tended and others are never attended. In order to reduce the
influence of the alignment error, we add a constraint based
on lexical translation table as follows. When a target word ej
aligns to a replaced source word ci, and this pair can be found
in the translation table, we will replace ej with the translation
of the original source word. Otherwise the target word ej will
be kept in the output.
