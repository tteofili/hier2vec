
In order to understand where the performance im-
provement comes from, we analyze the phrase pair
scores computed by the RNN Encoder–Decoder
against the corresponding p(f | e) from the trans-
lation model. Since the existing translation model
relies solely on the statistics of the phrase pairs in
the corpus, we expect its scores to be better esti-
mated for the frequent phrases but badly estimated
for rare phrases. Also, as we mentioned earlier
in Sec. 3.1, we further expect the RNN Encoder–
Decoder which was trained without any frequency
information to score the phrase pairs based rather
on the linguistic regularities than on the statistics
of their occurrences in the corpus.

We focus on those pairs whose source phrase is
long (more than 3 words per source phrase) and

As a result, the probability of words not in the shortlist is
always overestimated. It is possible to address this issue by
backing off to an existing model that contain non-shortlisted
words (see (Schwenk, 2007)) In this paper, however, we opt
for introducing a word penalty instead, which counteracts the
word probability overestimation.



Source Samples from RNN Encoder–Decoder
at the end of the [à la fin de la] (×11)
for the first time [pour la première fois] (×24) [pour la première fois que] (×2)
in the United States and [aux États-Unis et] (×6) [dans les États-Unis et] (×4)
, as well as [, ainsi que] [,] [ainsi que] [, ainsi qu’] [et UNK]
one of the most [l’ un des plus] (×9) [l’ un des] (×5) [l’ une des plus] (×2)

(a) Long, frequent source phrases

Source Samples from RNN Encoder–Decoder
, Minister of Communica-
tions and Transport

[ , ministre des communications et le transport] (×13)

did not comply with the [n’ tait pas conforme aux] [n’ a pas respect l’] (×2) [n’ a pas respect la] (×3)
parts of the world . [arts du monde .] (×11) [des arts du monde .] (×7)
the past few days . [quelques jours .] (×5) [les derniers jours .] (×5) [ces derniers jours .] (×2)
on Friday and Saturday [vendredi et samedi] (×5) [le vendredi et samedi] (×7) [le vendredi et le samedi] (×4)

(b) Long, rare source phrases

Table 3: Samples generated from the RNN Encoder–Decoder for each source phrase used in Table 2. We
show the top-5 target phrases out of 50 samples. They are sorted by the RNN Encoder–Decoder scores.

Figure 4: 2–D embedding of the learned word representation. The left one shows the full embedding
space, while the right one shows a zoomed-in view of one region (color–coded). For more plots, see the
supplementary material.

frequent. For each such source phrase, we look
at the target phrases that have been scored high
either by the translation probability p(f | e) or
by the RNN Encoder–Decoder. Similarly, we per-
form the same procedure with those pairs whose
source phrase is long but rare in the corpus.

Table 2 lists the top-3 target phrases per source
phrase favored either by the translation model
or by the RNN Encoder–Decoder. The source
phrases were randomly chosen among long ones
having more than 4 or 5 words.

In most cases, the choices of the target phrases
by the RNN Encoder–Decoder are closer to ac-
tual or literal translations. We can observe that the
RNN Encoder–Decoder prefers shorter phrases in
general.

Interestingly, many phrase pairs were scored
similarly by both the translation model and the
RNN Encoder–Decoder, but there were as many

other phrase pairs that were scored radically dif-
ferent (see Fig. 3). This could arise from the
proposed approach of training the RNN Encoder–
Decoder on a set of unique phrase pairs, discour-
aging the RNN Encoder–Decoder from learning
simply the frequencies of the phrase pairs from the
corpus, as explained earlier.

Furthermore, in Table 3, we show for each of
the source phrases in Table 2, the generated sam-
ples from the RNN Encoder–Decoder. For each
source phrase, we generated 50 samples and show
the top-five phrases accordingly to their scores.
We can see that the RNN Encoder–Decoder is
able to propose well-formed target phrases with-
out looking at the actual phrase table. Importantly,
the generated phrases do not overlap completely
with the target phrases from the phrase table. This
encourages us to further investigate the possibility
of replacing the whole or a part of the phrase table



Figure 5: 2–D embedding of the learned phrase representation. The top left one shows the full represen-
tation space (5000 randomly selected points), while the other three figures show the zoomed-in view of
specific regions (color–coded).

with the proposed RNN Encoder–Decoder in the
future.
