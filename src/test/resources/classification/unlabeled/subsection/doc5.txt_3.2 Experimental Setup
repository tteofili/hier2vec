
All neural models were initialized using the word-
embedding matrices from word2vec2. These ma-
trices were fine-tuned during training. Following
Kim (2014), we used filter windows of lengths 3,
4, 5 with 100 features maps each for the CNN clas-
sifier. For training it, we used Adadelta (Zeiler,
2012) with its default parameters. The BLSTM
network was trained with Adam (Kingma and Ba,
2014), with a learning rate of 10−4. In order to
have a similar number of parameters than in the
CNN (48 million approximately), we used 300

1www.statmt.org/wmt14/
2code.google.com/archive/p/word2vec

Table 1: Corpora main figures. (EMEA-Domain)
is the in-domain corpus, (Medical-Test) is the
evaluation data and (Medical-Mert) is the develop-
ment set. (Europarl) is the out-of-domain corpus.
M denotes millions of elements and k thousands of
elements, |S| stands for number of sentences, |W |
for number of words and |V | for vocabulary size.

Corpus |S| |W | |V |

EMEA-Domain EN 1.0M 12.1M 98.1kFR 14.1M 112k

Medical-Test EN 1000 21.4k 1.8kFR 26.9k 1.9k

Medical-Mert EN 501 9.9k 979FR 11.6k 1.0k

Medical-Domain DE 1.1M 10.9M 141kEN 12.9M 98.8k

Medical-Test DE 1000 18.2k 1.7kEN 19.2k 1.9k

Medical-Mert DE 500 8.6k 874EN 9.2k 979

Europarl EN 2.0M 50.2M 157kFR 52.5M 215k

Europarl DE 1.9M 44.6M 290kEN 47.8M 153k

units in each LSTM layer. 2 fully-connected lay-
ers of size 200 and 100 were introduced after the
CNN and BLSTM (see Section 1). All neural
models3 were implemented using Theano (Theano
Development Team, 2016). The number of sen-
tences selected at each iteration (r) should be em-
pirically determined. In our experiments, we set
r = 50, 000.

All SMT experiments were carried out us-
ing the open-source phrase-based SMT toolkit
Moses (Koehn et al., 2007). The language model
used was a 5-gram, standard in SMT research,
with modified Kneser-Ney smoothing (Kneser and
Ney, 1995), built with the SRILM toolkit (Stol-
cke, 2002). The phrase table was generated by
means of symmetrised word alignments obtained
with GIZA++ (Och and Ney, 2003). The log-
lineal combination weights λ were optimized us-
ing MERT (minimum error rate training) (Och,
2003). Since MERT requires a random initialisa-
tion of λ that often leads to different local optima
being reached, every result of this paper consti-
tutes the average of 10 repetitions, with the pur-
pose of providing robustness to the results. In the

3Source code available at https://github.com/
lvapeab/sentence-selectioNN.

code.google.com/archive/p/word2vec
https://github.com/lvapeab/sentence-selectioNN
https://github.com/lvapeab/sentence-selectioNN


Table 2: Summary of best results obtained. Columns denote, from left to right: selection strategy, BLEU,
number of sentences, given in terms of the in-domain corpus size, and (+) selected sentences.

EN-FR FR-EN
Strategy BLEU # Sentences BLEU # Sentences

baseline-emea 28.6± 0.2 1.0M 29.9± 0.2 1.0M
bsln-emea-euro 29.4± 0.1 1.0M+1.5M 32.4± 0.1 1.0M+1.5M
Random 29.4± 0.4 1.0M+500k 32.3± 0.3 1.0M+500k

Cross-Entropy 29.8± 0.1 1.0M+450k 31.8± 0.1 1.0M+600k
BLSTM 29.9± 0.3 1.0M+300k 32.3± 0.1 1.0M+500k
CNN 29.8± 0.2 1.0M+450k 32.3± 0.2 1.0M+350k

DE-EN EN-DE
Strategy BLEU # Sentences BLEU # Sentences

baseline-emea 23.7± 0.2 1.0M 15.6± 0.1 1.0M
bsln-emea-euro 26.2± 0.3 1.0M+1.5M 16.6± 0.2 1.0M+1.5M
Random 25.5± 0.1 1.0M+600k 16.8± 0.1 1.0M+550k

Cross-Entropy 25.5± 0.3 1.0M+600k 16.8± 0.2 1.0M+500k
BLSTM 25.9± 0.1 1.0M+500k 17.1± 0.2 1.0M+400k
CNN 25.9± 0.1 1.0M+400k 16.9± 0.1 1.0M+350k

tables, 95% confidence intervals of these repeti-
tions are shown. SMT output was evaluated by
means of BLEU (Papineni et al., 2002).

We compared the selection methods with two
baseline systems. The first one was obtained by
training the SMT system with in-domain training
data (EMEA-Domain data). We will refer to this
setup with the name of baseline-emea. A
second baseline experiment has been carried out
with the concatenation of the Europarl corpus and
EMEA training data (i.e., all the data available).
We will refer to this setup as bsln-emea-euro.
In addition, we also included results for a purely
random sentence selection without replacement.
